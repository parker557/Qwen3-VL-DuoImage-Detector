ref输入图路径,ref输入图大小（H*W）,输入图路径,输入图大小（H*W）,推理结果（只记录第一个结果）,推理时间（平均时间）,提示词
input/test1_ref.jpg,513*359,input/test1.jpg,903*1123,"{""label"": ""target_object"", ""bbox_qwen1000"": [151.0, 110.0, 512.0, 430.0], ""bbox_2d"": [170, 99, 575, 388]}",8.2745,"根据以上两张图片。第一张图片展示了一个目标物体。第二张图片包含了多个目标物体，\n请分析第一张图片中的目标物体，然后在第二张图片中找出所有相同类型的物体，并为每个检测到的物体输出边界框。\n请只返回 JSON，不要多余解释、前后缀或 Markdown 代码块,且label统一使用“target_object”。\nJSON 格式（示例值仅作结构参考）：\n{\n  ""results"": [\n    { ""bbox"": [480,365,610,440], ""label"": ""target_object"" },\n    { ""bbox"": [580,375,775,480], ""label"": ""target_object"" }\n  ]\n}"
input/test1_ref.jpg,513*359,input/test1.jpg,903*1123,"{""label"": ""target_object"", ""bbox_qwen1000"": [150.0, 105.0, 500.0, 420.0], ""bbox_2d"": [168, 95, 562, 379]}",8.3858,"根据以上两张图片。第一张图片展示了一个目标物体。第二张图片包含了多个目标物体，\n请分析第一张图片中的目标物体，然后在第二张图片中找出所有相同类型的物体，并为每个检测到的物体输出边界框。\n请只返回 JSON，不要多余解释、前后缀或 Markdown 代码块,且label统一使用“target_object”。\nJSON 格式（示例值仅作结构参考）：\n{\n  ""results"": [\n    { ""bbox"": [480,365,610,440], ""label"": ""target_object"" },\n    { ""bbox"": [580,375,775,480], ""label"": ""target_object"" }\n  ]\n}"
input/test2_ref.png,966*532,input/test2.jpg,738*1159,"{""label"": ""target_object"", ""bbox_qwen1000"": [35.0, 247.0, 315.0, 890.0], ""bbox_2d"": [41, 182, 365, 657]}",2.9555,"根据以上两张图片。第一张图片展示了一个目标物体。第二张图片包含了多个目标物体，\n请分析第一张图片中的目标物体，然后在第二张图片中找出所有相同类型的物体，并为每个检测到的物体输出边界框。\n请只返回 JSON，不要多余解释、前后缀或 Markdown 代码块,且label统一使用“target_object”。\nJSON 格式（示例值仅作结构参考）：\n{\n  ""results"": [\n    { ""bbox"": [480,365,610,440], ""label"": ""target_object"" },\n    { ""bbox"": [580,375,775,480], ""label"": ""target_object"" }\n  ]\n}"
input/test1_ref.jpg,513*359,input/test1.jpg,903*1123,"{""label"": ""target_object"", ""bbox_qwen1000"": [151.0, 110.0, 512.0, 430.0], ""bbox_2d"": [170, 99, 575, 388]}",8.1631,"根据以上两张图片。第一张图片展示了一个目标物体。第二张图片包含了多个目标物体，\n请分析第一张图片中的目标物体，然后在第二张图片中找出所有相同类型的物体，并为每个检测到的物体输出边界框。\n请只返回 JSON，不要多余解释、前后缀或 Markdown 代码块,且label统一使用“target_object”。\nJSON 格式（示例值仅作结构参考）：\n{\n  ""results"": [\n    { ""bbox"": [480,365,610,440], ""label"": ""target_object"" },\n    { ""bbox"": [580,375,775,480], ""label"": ""target_object"" }\n  ]\n}"
input/test2_ref.png,966*532,input/test2.jpg,738*1159,"{""label"": ""target_object"", ""bbox_qwen1000"": [35.0, 247.0, 310.0, 888.0], ""bbox_2d"": [41, 182, 359, 655]}",2.8863,"根据以上两张图片。第一张图片展示了一个目标物体。第二张图片包含了多个目标物体，\n请分析第一张图片中的目标物体，然后在第二张图片中找出所有相同类型的物体，并为每个检测到的物体输出边界框。\n请只返回 JSON，不要多余解释、前后缀或 Markdown 代码块,且label统一使用“target_object”。\nJSON 格式（示例值仅作结构参考）：\n{\n  ""results"": [\n    { ""bbox"": [480,365,610,440], ""label"": ""target_object"" },\n    { ""bbox"": [580,375,775,480], ""label"": ""target_object"" }\n  ]\n}"
input/test1_ref.jpg,513*359,input/test1.jpg,903*1123,"{""label"": ""target_object"", ""bbox_qwen1000"": [148.0, 110.0, 510.0, 420.0], ""bbox_2d"": [166, 99, 573, 379]}",7.3051,"根据以上两张图片。第一张图片展示了一个目标物体。第二张图片包含了多个目标物体，\n请分析第一张图片中的目标物体，然后在第二张图片中找出所有相同类型的物体，并为每个检测到的物体输出边界框。\n请只返回 JSON，不要多余解释、前后缀或 Markdown 代码块,且label统一使用“target_object”\n\n1.如果待搜索类是二次元立牌，直接框出全部立牌，无论是什么角色。\n\nJSON 格式（示例值仅作结构参考）：\n{\n  ""results"": [\n    { ""bbox"": [480,365,610,440], ""label"": ""target_object"" },\n    { ""bbox"": [580,375,775,480], ""label"": ""target_object"" }\n  ]\n}\n"
input/test2_ref.png,966*532,input/test2.jpg,738*1159,"{""label"": ""target_object"", ""bbox_qwen1000"": [30.0, 250.0, 350.0, 880.0], ""bbox_2d"": [35, 184, 406, 649]}",9.5081,"根据以上两张图片。第一张图片展示了一个目标物体。第二张图片包含了多个目标物体，\n请分析第一张图片中的目标物体，然后在第二张图片中找出所有相同类型的物体，并为每个检测到的物体输出边界框。\n请只返回 JSON，不要多余解释、前后缀或 Markdown 代码块,且label统一使用“target_object”\n\n1.如果待搜索类是二次元立牌，直接框出全部立牌，无论是什么角色。\n\nJSON 格式（示例值仅作结构参考）：\n{\n  ""results"": [\n    { ""bbox"": [480,365,610,440], ""label"": ""target_object"" },\n    { ""bbox"": [580,375,775,480], ""label"": ""target_object"" }\n  ]\n}\n"
